{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_first_assignment_MC886.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martadftese/hello-world/blob/master/code_first_assignment_MC886.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIz66SYdRB0k",
        "colab_type": "code",
        "outputId": "968128c9-25f2-4d4c-ca15-67f7202189c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "# ================================== TestLinearRegression.py ======================================\n",
        "\n",
        "import unittest\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from LinearRegression import LinearRegressionLearner\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import Utils\n",
        "import math\n",
        "\n",
        "class LinearRegressionLearnerTestCase(unittest.TestCase):\n",
        "    def load_diabetes_data(self):\n",
        "        diabetes = datasets.load_diabetes()\n",
        "\n",
        "        # Split the data into training/testing sets\n",
        "        self.X_Train = diabetes.data[:-20]\n",
        "        self.X_Test = diabetes.data[-20:]\n",
        "\n",
        "        # Split the targets into training/testing sets\n",
        "        self.Y_Train = diabetes.target[:-20]\n",
        "        self.Y_Test = diabetes.target[-20:]\n",
        "\n",
        "\n",
        "    def load_metro_traffic_data(self):\n",
        "        self.X_Train, self.Y_Train, self.X_Test, self.Y_Test = \\\n",
        "            Utils.load_and_hot_encode('Metro_Interstate_Traffic_Volume.csv',\n",
        "                                      'Metro_Interstate_Traffic_Volume_formatted.csv',\n",
        "                                      'Metro_Interstate_Traffic_Volume_formatted_headers.csv')\n",
        "\n",
        "\n",
        "    def test_learning_dataset(self):\n",
        "        self.load_metro_traffic_data()\n",
        "        # self.load_diabetes_data()\n",
        "        number_of_iterations = 1000\n",
        "        learning_rate = 0.1\n",
        "        batch_size = int(len(self.X_Test)/4)\n",
        "\n",
        "        print('X_Train shape: ', np.shape(self.X_Train))\n",
        "        print('Y_Train shape: ', np.shape(self.Y_Train))\n",
        "        print('X_Test shape: ', np.shape(self.X_Test))\n",
        "        print('Y_Test shape: ', np.shape(self.Y_Test))\n",
        "\n",
        "        regr = linear_model.SGDRegressor(max_iter=number_of_iterations)\n",
        "        regr.fit(self.X_Train, self.Y_Train)\n",
        "        lib_y_pred = regr.predict(self.X_Test)\n",
        "\n",
        "        print(\"=============================== LIB =================================\")\n",
        "        print('Coefficients: \\n', regr.coef_)\n",
        "        lib_error = math.sqrt(mean_squared_error(self.Y_Test, lib_y_pred))\n",
        "        print(\"Root Mean squared error: %.2f\" % lib_error)\n",
        "        print('Variance score: %.2f' % r2_score(self.Y_Test, lib_y_pred))\n",
        "\n",
        "        learner = LinearRegressionLearner()\n",
        "        learner.set_normalize_data(False)\n",
        "        costs = learner.fit(self.X_Train, self.Y_Train, number_of_iterations, learning_rate, batch_size)\n",
        "        my_y_pred_test = [learner.predict(example) for example in self.X_Test]\n",
        "        my_y_pred_train = [learner.predict(example) for example in self.X_Train]\n",
        "\n",
        "        pyplot.plot(range(int(len(costs)/4)), costs[:int(len(costs)/4)])\n",
        "        pyplot.xlabel(\"Number of iterations\")\n",
        "        pyplot.ylabel(\"Cost\")\n",
        "        pyplot.show()\n",
        "\n",
        "        print(\"=============================== MY ===================================\")\n",
        "        print('Coefficients: %s' % learner.parameters)\n",
        "        # Results test\n",
        "        my_error_test = math.sqrt(mean_squared_error(self.Y_Test, my_y_pred_test))\n",
        "        print(\"Test Root Mean squared error: %.2f\" % my_error_test)\n",
        "        print('Test Variance score: %.2f' % r2_score(self.Y_Test, my_y_pred_test))\n",
        "        # Results train\n",
        "        my_error_train = math.sqrt(mean_squared_error(self.Y_Train, my_y_pred_train))\n",
        "        print(\"Train Root Mean squared error: %.2f\" % my_error_train)\n",
        "        print('Train Variance score: %.2f' % r2_score(self.Y_Train, my_y_pred_train))\n",
        "\n",
        "        self.assertTrue(True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()\n",
        "\n",
        "# ==================================== LineaRegression.py ======================================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LinearRegressionLearner:\n",
        "    def __init__(self):\n",
        "        self.learning_rate = 0\n",
        "        self.number_of_parameters = 0\n",
        "        self.parameters = np.array([])\n",
        "        self.number_of_features = 0\n",
        "        self.normalization_means = np.array([])\n",
        "        self.normalization_deviations = np.array([])\n",
        "        self.normalize_data = False\n",
        "        self.number_of_examples = 0\n",
        "        self.batch_size = 0\n",
        "        self.inputs = np.array([])\n",
        "        self.number_of_inputs = 0\n",
        "\n",
        "    \"\"\"\n",
        "        The data should be an row vector\n",
        "        this returns the data normalized using x(i) = (x(i) - mean / std_deviation)\n",
        "    \"\"\"\n",
        "    def normalize(self, data):\n",
        "        return (data - self.normalization_means) / self.normalization_deviations\n",
        "\n",
        "    def set_normalize_data(self, should_normalize):\n",
        "        self.normalize_data = should_normalize\n",
        "\n",
        "    def find_normalization_params(self, inputs):\n",
        "        self.normalization_means = np.mean(inputs, axis=0)\n",
        "        self.normalization_deviations = np.std(inputs, axis=0)\n",
        "\n",
        "    def adapt_inputs(self):\n",
        "        if self.normalize_data:\n",
        "            self.find_normalization_params(self.inputs)\n",
        "            self.inputs = np.array([self.normalize(example) for example in self.inputs])\n",
        "        self.inputs = np.c_[np.ones((self.number_of_examples, 1)), self.inputs]\n",
        "\n",
        "    def save_algorithm_params(self, inputs, batch_size, learning_rate):\n",
        "        self.inputs = inputs\n",
        "        self.number_of_examples, self.number_of_features = np.shape(inputs)\n",
        "        if batch_size == -1:\n",
        "            self.batch_size = self.number_of_examples\n",
        "        else:\n",
        "            self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.number_of_parameters = self.number_of_features + 1\n",
        "        self.parameters = np.random.rand(self.number_of_parameters, )\n",
        "\n",
        "    def fit(self, inputs, outputs, number_of_iterations, learning_rate, batch_size=-1):\n",
        "        self.save_algorithm_params(inputs, batch_size, learning_rate)\n",
        "        self.adapt_inputs()\n",
        "        cost_per_iteration = []\n",
        "        for iteration in range(number_of_iterations):\n",
        "            permutation = np.random.permutation(self.batch_size)\n",
        "            input_batch = self.inputs[permutation]\n",
        "            output_batch = outputs[permutation]\n",
        "            self.parameters = self.parameters - self.learning_rate * input_batch.T.dot(input_batch.dot(self.parameters) - output_batch) / self.batch_size\n",
        "            #cost_per_iteration.append(self.current_cost(input_batch, output_batch))\n",
        "        return cost_per_iteration\n",
        "\n",
        "    def current_cost(self, inputs, outputs):\n",
        "        return ((inputs.dot(self.parameters) - outputs).sum())**2 / (2 * len(inputs))\n",
        "\n",
        "    def predict(self, input):\n",
        "        if self.normalize_data:\n",
        "            input = self.normalize(input)\n",
        "        return self.parameters[0] + self.parameters[1:].T.dot(input)\n",
        "\n",
        "# ========================================= Utils.py =============================================\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "\n",
        "def apply_hot_encoding(data, headers):\n",
        "    encoded_data = np.empty((1, len(data)))\n",
        "    new_headers = np.array([])\n",
        "    for column, header in zip(data.T, headers):\n",
        "        is_category = isinstance(column[0], str)\n",
        "        if not is_category:\n",
        "            encoded_data = np.vstack((encoded_data, column))\n",
        "            new_headers = np.append(new_headers, header)\n",
        "        elif re.match('([0-9]{4})-([0-9]{2})-([0-9]{2}) (.*)', column[0]):\n",
        "            dates = np.array([pd.Timestamp(date_str) for date_str in column])\n",
        "            # Hot encode week day i.e. monday, thursday, wednesday, tuesday, friday, saturday, sunday\n",
        "            days_of_week = np.array(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
        "            date_column = np.array([date.day_name() for date in dates])\n",
        "            encoded_data, new_headers = encode_categories(encoded_data, new_headers, days_of_week, date_column)\n",
        "            # Hot encode hour of day\n",
        "            hours_of_day_column = np.array([hour_of_day(date) for date in dates])\n",
        "            hours_of_day = np.array(['%dth' % hour for hour in range(24)])\n",
        "            encoded_data, new_headers = encode_categories(encoded_data, new_headers,\n",
        "                                                          hours_of_day, hours_of_day_column)\n",
        "        else:\n",
        "            encoded_data, new_headers = encode_categories(encoded_data, new_headers,\n",
        "                                                          np.unique(column), column)\n",
        "\n",
        "    return encoded_data[1:].T, new_headers\n",
        "\n",
        "\n",
        "def encode_categories(encoded_data, new_headers, categories, data):\n",
        "    for category in categories:\n",
        "        new_column = np.array([int(category == value) for value in data])\n",
        "        encoded_data = np.vstack((encoded_data, new_column))\n",
        "        new_headers = np.append(new_headers, category)\n",
        "    return encoded_data, new_headers\n",
        "\n",
        "\n",
        "def part_of_day(date):\n",
        "    if 0 <= date.hour < 2:\n",
        "        return 'Early Dawn'\n",
        "    elif 3 <= date.hour < 5:\n",
        "        return 'Late Dawn'\n",
        "    elif 5 <= date.hour < 9:\n",
        "        return 'Early Morning'\n",
        "    elif 10 <= date.hour < 12:\n",
        "        return 'Late Morning'\n",
        "    elif 12 <= date.hour < 15:\n",
        "        return 'Early Afternoon'\n",
        "    elif 15 <= date.hour < 19:\n",
        "        return 'Late Afternoon'\n",
        "    elif 19 <= date.hour < 22:\n",
        "        return 'Early Night'\n",
        "    elif 22 <= date.hour <= 23:\n",
        "        return 'Late Night'\n",
        "\n",
        "def hour_of_day(date):\n",
        "    return '%dth' % date.hour\n",
        "\n",
        "\n",
        "def generate_gif_for_path(path=os.getcwd(), name='movie', duration=0.04):\n",
        "    image_folder = os.fsencode(path)\n",
        "    filenames = []\n",
        "    for file in os.listdir(image_folder):\n",
        "        filename = os.fsdecode(file)\n",
        "        if filename.endswith( ('.jpeg', '.png', '.gif') ):\n",
        "            filenames.append(filename)\n",
        "\n",
        "    filenames.sort() # this iteration technique has no built in order, so sort the frames\n",
        "    images = list(map(lambda filename: imageio.imread(filename), filenames))\n",
        "    imageio.mimsave(os.path.join('%s.gif' % name), images, duration = duration) # modify duration as needed\n",
        "\n",
        "def isWeekDay(data):\n",
        "    return not isWeekendDay(data)\n",
        "\n",
        "def isWeekendDay(data):\n",
        "    date = pd.Timestamp(data[len(data) - 2])\n",
        "    return data[0] != 'None' or date.day_name() == 'Saturday' or date.day_name() == 'Sunday'\n",
        "\n",
        "def load_and_hot_encode(file_path, output_path, headers_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    data_array = data.to_numpy()\n",
        "    data_array = np.array(list(filter(isWeekDay, data_array)))\n",
        "    np.random.shuffle(data_array)\n",
        "    data_rows, data_columns = np.shape(data_array)\n",
        "    formatted_data, headers = apply_hot_encoding(data_array[:, :data_columns - 1], data.head())\n",
        "    np.savetxt(output_path, formatted_data, delimiter=',', fmt='%1.2f')\n",
        "    # Save headers\n",
        "    np.savetxt(headers_path, headers, delimiter=',', fmt='%s')\n",
        "    # Check params\n",
        "    formatted_data_rows, formatted_data_columns = np.shape(formatted_data)\n",
        "    assert (formatted_data_rows == data_rows)\n",
        "    # Prepare separation\n",
        "    percentage_of_training_data = 0.90\n",
        "    # Separate training data\n",
        "    x_train = formatted_data[:int(data_rows * percentage_of_training_data), :formatted_data_columns]\n",
        "    y_train = np.ravel(\n",
        "        data_array[:int(data_rows * percentage_of_training_data), data_columns - 1:data_columns])\n",
        "    np.savetxt(\"Training_X.csv\", x_train, delimiter=',', fmt='%1.2f')\n",
        "    np.savetxt(\"Training_Y.csv\", y_train, delimiter=',', fmt='%1.2f')\n",
        "    # Separate test data\n",
        "    x_test = formatted_data[int(data_rows * percentage_of_training_data):, :formatted_data_columns]\n",
        "    y_test = np.ravel(\n",
        "        data_array[int(data_rows * percentage_of_training_data):, data_columns - 1:data_columns])\n",
        "    np.savetxt(\"Test_X.csv\", x_test, delimiter=',', fmt='%1.2f')\n",
        "    np.savetxt(\"Test_Y.csv\", y_test, delimiter=',', fmt='%1.2f')\n",
        "    return (x_train, y_train, x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2bf986a8ab92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLinearRegression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegressionLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'LinearRegression'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cc9uAlwXStr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}